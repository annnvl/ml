\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[russian]{babel}
\usepackage[left=2cm,right=2cm,
    top=2cm,bottom=2cm,bindingoffset=0cm]{geometry}


\title{Машинное обучение. Задание 4\\*Теоретические задачи.}
\author{Анна Власова, 497}
\date{}

\begin{document}

\maketitle

\section*{3.1 Знакомство с линейным классификатором}
1. Пусть x - вектор признаков (включая константный), w - вектор весов, а $\hat y \in \{-1; 1\}$ - предсказаный класс, тогда бинарный линейный классификатор можно записать как: $$ \hat y = sign(\lange x, w \range) = f(x, w)$$ 

2. Отступом алгоритма на объекте $x_i$ называется величина $$M_i(w) = y_i \hat y(x_i) = y_i \cdot \lange x_i, w \range $$ 
где y - правильный класс для x. Отступ отрицателен тогда и только тогда, когда алгоритм ошибается на объекте

3. В вектор x добавляется константный признак $x_0 = -1$, тогда при добавлении $w_0$ к вектору весов первое выражение сводится ко второму.

4. Эмпирический риск: $$Q(w) = \frac{1}{n} \sum_{i=1}^{n} [\hat y(x_i) \not= y_i] = \frac{1}{n} \sum_{i=1}^{n} [M_i \le 0] $$ Для наилучшего алгоритма он равен 0.

5. $w \equiv 0$

6. $$ Q(a, X^n) = \frac{1}{n} \sum_{i=1}{n} L(M)$$

7. Функция потерь соответствует величине ошибки алгоритма на объекте. Она неотрицательная. В случае линейной классификации, если смотреть на функцию потерь как на функцию от отступа, то она будет невозрастающей. Для удобства оптимизации часто берут выпуклую функцию.

8. $L(M) = [M \le 0]$

9. Регуляризатор штрафует модель за излишнюю сложность, например,за очень большие по модулю веса. Примеры:
$L_1:$ $$ R(w) = \alpha \sum_i |w_i|$$
$L_2:$ $$ R(w) = \alpha \sum_i w_i^2$$
$L_0:$ $$ R(w) = \alpha \sum_i [w_i \not=0]$$

10. При переобучении ошибка на тестовой выборке значительно меньше ошибки на обучающей выборке, поэтому такой алгоритм обладает низкой обобщающей способностью, но из плохой обобщающей способности не следует, что алгоритм переобучен, он может быть, например, недообучен. Часто если модель становится слишком сложной (например, в ней появляются очень большие по модулю веса) это может говорить о переобучении. Во многих таких случаях регуляризация может помочь, избавившись от переобучения и увеличив обобщающую способность.

11.Даже мелое перемещение из такого минимума дает сильное возрастание функционала аппроксимированного эмпирического риска и поэтому другие параметры не могут себя проявить.

12. Увеличивает при приближении или выходе параметров алгоритма за допустимые границы.

13. С регуляризацией, тк она увеличивает значение функционала риска

14. Может и с регуляризацией, если переобучение было не сильным, и ошибка на переобученном алгоритме была меньше той ошибки, которая появилась за счет изменения весов при регуляризации. Может и без нее, если алгоритм был сильно переобучен, и регуляризация его хорошо скорректировала.

15. Рассмотрим задачу бинарной классификации. И обозначим классы как $\{0, 1\}$ И Пусть 
TP - количество верно классифицированных объектов класса 1
FN - количество неверно классифицированных объектов класса 1
TN - количество верно классифицированных объектов класса 0
FP - количество неверно классифицированных объектов класса 0
P - количество объектов класса 1
N - количество объектов класса 0
Тогда $$ Accuracy = \frac{TP +TN}{P+N}$$ $$Precision = \frac{TP}{TP+FP}$$ $$ Recall = \frac{TP}{P}$$

16. Обозначим $$TPR = \frac{TP}{P}$$ $$FPR = \frac{FP}{P}$$
Тогда ROC-кривая -- зависимость TPR(FPR). A AUC-метрика -- площидь под этой кривой.

17. Проходим в цикле по всем объектам, классифицированным как фамилии. И на каждом шаге добавляем на график новую точку. $(TPR_0, FPR_0) = (0,0) $ Пусть $(FPR_i, TPR_i)$ - точка, полученная на предыдущем шаге, тогда

а) если текущий объект действительно фамилия, то $(FPR_{i+1}, TPR_{i+1}) = (FPR_i, TPR_i + \frac{1}{P})$

б) если текущий объект на самом деле не фамилия, то $(FPR_{i+1}, TPR_{i+1}) = (FPR_i + \frac{1}{N}, TPR_i)$

где P, N - количество фамилий и не фамилий в выборке соответственно.

\section*{3.2 Вероятностный смысл регуляризаторов}

Пусть $X \dot Y$ - вероятностное пространство, а также задана параметрическая модель совместной плотности расределений объектов и классов $p(x, y|w)$. Введем параметрической семейство априорных распределений $p(w, \gamma)$, где $\gamma$ - гиперпараметр. 
Тогда будем считать, что выборка может быть порождена каждой из плотностей $p(x, y|w)$ c параметризованной $\gamma$ вероятностью $p(w, \gamma)$.
Воспользуемся принципом максимального правдоподобия для совместного распределения данных и модели: $$L_\gamma(w, X^n) = ln p(x^n, w, \gamma) = \sum_{i=1}^{n}ln p(x_i, y_i|w) + ln p(w, \gamma) \arrow \max_w$$ Если положить $$-ln p(x_i, y_i|w) = L(y_i f(x_i, w)) $$ $$ln p(w, \gamma) = \gamma R(w)$$ Тогда принцип минимизации аппроксимированного эмпирического риска
$$Q(w, X) = \sum_{i=1}^{n}L(y_i f(x_i, w)) + \gamma R(w) \arrow \min_w$$
Эквивалентен принципу максимизации правдоподобия, приведенного выше, то есть получается, что регуляризатор $R(w)$ соответствует параметрическому семейству априорных распределений параметров моделей.

\subsection*(L_1)

\end{document}











